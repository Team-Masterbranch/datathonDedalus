# main.py

## Overview
Main entry point for the healthcare data analysis system. Initializes and starts the application.

## Functions

### main()
Initializes the Application instance and starts the application.
- Creates an instance of the Application class
- Calls the start() method to begin execution

## Usage
The script uses a standard Python entry point pattern with `if __name__ == "__main__"` to ensure the main() function is only executed when the script is run directly.


# application.py

## Overview
Application service layer that coordinates between different components of the system. Acts as the central orchestrator managing interactions between the CLI interface, query processing, and data management components.

## Classes

### Application
Main application class that initializes and manages all core components.

#### Properties
- `preprocessor`: Instance of QueryPreprocessor for initial query processing
- `parser`: Instance of Parser for query parsing
- `llm_handler`: Instance of LLMHandler for LLM interactions
- `data_manager`: Instance of DataManager for handling data operations
- `query_manager`: Instance of QueryManager for executing queries
- `cli`: Instance of HealthcareCLI for command-line interface

#### Methods

##### __init__()
Initializes all core components and sets up the data directory path.

##### start()
Starts the application by initiating the command-line interface loop.
- Handles KeyboardInterrupt for graceful shutdown
- Includes error handling and logging
- Calls shutdown() on exit

##### shutdown()
Performs cleanup operations when the application is closing.

##### async process_user_query(query: str, filter_current_cohort: bool = False) -> Dict[str, Any]
Processes and executes a user's query.
- Preprocesses the query
- Uses LLM if needed
- Executes the query through QueryManager
- Returns query results as a dictionary
- Parameters:
  - query: The user's input query string
  - filter_current_cohort: Boolean flag to filter current cohort or start new search

##### get_available_tests() -> List[str]
Returns a list of available test files in the tests directory.
- Excludes .py extension
- Returns only files starting with 'test_'

##### get_test_functions(test_file: str) -> List[str]
Retrieves all test functions from a specific test file.
- Uses AST parsing to avoid importing test files
- Returns only functions starting with 'test_'
- Parameters:
  - test_file: Name of the test file without .py extension

##### run_tests(test_file: Optional[str] = None, test_function: Optional[str] = None) -> Dict[str, Any]
Executes specified tests using pytest.
- Can run all tests, specific test file, or specific test function
- Returns dictionary with test execution results
- Parameters:
  - test_file: Optional specific test file to run
  - test_function: Optional specific test function to run

# query_preprocessor.py

## Overview
First stage of query processing pipeline. Attempts to parse queries using cache or regex before requiring LLM processing. This helps reduce unnecessary LLM calls by catching common or previously processed queries.

## Classes

### QueryPreprocessor
Handles initial query processing and caching.

#### Properties
- `cache`: Dictionary storing previously processed queries and their results

#### Methods

##### __init__()
Initializes the preprocessor with an empty cache.
- Sets up logging

##### process_query(raw_query: str) -> tuple[str, bool]
Main processing method that determines if a query needs LLM processing.
- Checks cache first
- Attempts regex matching if not in cache
- Returns tuple containing:
  - processed query or structured criteria
  - boolean flag indicating if LLM processing is needed
- Parameters:
  - raw_query: Raw query string from CLI

##### _check_cache(query: str) -> Optional[str]
Internal method to check if query exists in cache.
- Returns cached result if found, None otherwise
- Parameters:
  - query: Query string to look up in cache

##### _try_regex_match(query: str) -> Optional[str]
Internal method to attempt matching query against regex patterns.
- Currently a stub returning None
- Parameters:
  - query: Query string to match against patterns

##### update_cache(query: str, structured_criteria: str) -> None
Updates cache with processed query result from LLM.
- Stores mapping between original query and structured form
- Parameters:
  - query: Original raw query
  - structured_criteria: Structured criteria from LLM

# query_preprocessor.py

## Overview
First stage of query processing pipeline. Attempts to parse queries using cache or regex before requiring LLM processing. This helps reduce unnecessary LLM calls by catching common or previously processed queries.

## Classes

### QueryPreprocessor
Handles initial query processing and caching.

#### Properties
- `cache`: Dictionary storing previously processed queries and their results

#### Methods

##### __init__()
Initializes the preprocessor with an empty cache.
- Sets up logging

##### process_query(raw_query: str) -> tuple[str, bool]
Main processing method that determines if a query needs LLM processing.
- Checks cache first
- Attempts regex matching if not in cache
- Returns tuple containing:
  - processed query or structured criteria
  - boolean flag indicating if LLM processing is needed
- Parameters:
  - raw_query: Raw query string from CLI

##### _check_cache(query: str) -> Optional[str]
Internal method to check if query exists in cache.
- Returns cached result if found, None otherwise
- Parameters:
  - query: Query string to look up in cache

##### _try_regex_match(query: str) -> Optional[str]
Internal method to attempt matching query against regex patterns.
- Currently a stub returning None
- Parameters:
  - query: Query string to match against patterns

##### update_cache(query: str, structured_criteria: str) -> None
Updates cache with processed query result from LLM.
- Stores mapping between original query and structured form
- Parameters:
  - query: Original raw query
  - structured_criteria: Structured criteria from LLM

# llm_handler.py

## Overview
Handles all interactions with the LLM service. Manages API calls, parameter configuration, and response processing. Currently implemented with stub methods for future LLM API integration.

## Classes

### LLMHandler
Manages LLM service interactions and configurations.

#### Properties
- `api_key`: API key for LLM service access
- `default_params`: Dictionary of default parameters for LLM queries containing:
  - temperature: 0.7
  - max_tokens: 150
  - top_p: 1.0
  - frequency_penalty: 0.0
  - presence_penalty: 0.0

#### Methods

##### __init__()
Initializes the LLM handler.
- Sets up logging
- Loads API key from configuration
- Initializes default parameters
- Raises ValueError if API key not configured

##### async process_query(query: str, params: Optional[Dict[str, Any]] = None) -> str
Main method for processing queries through the LLM.
- Merges default and custom parameters
- Handles logging and error management
- Parameters:
  - query: Query string to process
  - params: Optional parameters to override defaults
- Returns: LLM response string

##### async _send_to_llm(query: str, params: Dict[str, Any]) -> str
Internal method for actual LLM API communication.
- Currently returns mock responses
- TODO: Implement actual LLM API calls
- Parameters:
  - query: Processed query string
  - params: Complete parameter dictionary
- Returns: LLM response (currently mock)

##### update_default_params(params: Dict[str, Any]) -> None
Updates default parameters for LLM queries.
- Merges provided parameters with existing defaults
- Parameters:
  - params: Dictionary of parameters to update

##### @staticmethod format_prompt(query: str) -> str
Formats raw query into proper LLM prompt.
- Currently uses basic healthcare query template
- TODO: Implement proper prompt formatting
- Parameters:
  - query: Raw query string
- Returns: Formatted prompt string


# data_manager.py

## Overview
Centralized data management component for clinical datasets. Handles data loading, cleaning, filtering and schema management. Maintains both full dataset and current filtered cohort.

## Classes

### DataManager
Manages clinical datasets and provides filtering capabilities.

#### Properties
- `_data_path`: Path to directory containing CSV files
- `_full_dataset`: Complete dataset loaded from CSV files (pandas DataFrame)
- `_current_cohort`: Currently filtered subset of data (pandas DataFrame)
- `_full_schema`: Schema information for the full dataset
- `_current_schema`: Schema information for the current cohort

#### Methods

##### __init__(data_path: str)
Initializes DataManager and loads data.
- Parameters:
  - data_path: Directory containing CSV files
- Raises:
  - ValueError if data loading fails
- Automatically loads data and initializes schema

##### load_csv_files() -> bool
Loads and combines all CSV files from data directory.
- Returns: True if loading successful, False otherwise
- Logs loading progress and errors
- Combines multiple CSV files into single DataFrame

##### _update_full_schema()
Updates schema information for the full dataset.
- Internal method called after data loading

##### _update_current_schema()
Updates schema information for the current filtered cohort.
- Internal method called after applying filters

##### _create_schema(df: pd.DataFrame) -> Dict[str, Dict]
Creates schema dictionary for given DataFrame.
- Parameters:
  - df: DataFrame to analyze
- Returns: Dictionary containing:
  - dtype: Column data type
  - unique_values: Count of unique values
  - missing_values: Count of null values

##### get_full_schema() -> Dict[str, Dict]
Returns schema information for the full dataset.

##### get_current_schema() -> Dict[str, Dict]
Returns schema information for the current cohort.

##### get_current_cohort() -> Optional[pd.DataFrame]
Returns the current filtered dataset.

##### reset_to_full()
Resets current cohort to include all data.
- Creates fresh copy of full dataset
- Updates current schema

##### apply_filter(criteria: Dict[str, Any]) -> Optional[pd.DataFrame]
Applies filtering criteria to current cohort.
- Parameters:
  - criteria: Dictionary containing:
    - field: Column name
    - operation: 'greater_than', 'less_than', or 'equals'
    - value: Filter value
- Returns: Filtered DataFrame or None if error
- Supports operations:
  - greater_than
  - less_than
  - equals
- Updates current schema after filtering



# query_manager.py

## Overview
Manages query execution on pandas DataFrames using DataManager. Acts as an intermediary between parsed queries and data operations, handling cohort filtering and maintaining query state.

## Classes

### QueryManager
Manages query execution and maintains query state.

#### Properties
- `data_manager`: Instance of DataManager for data operations
- `last_query`: Dictionary storing the most recently executed query criteria

#### Methods

##### __init__(data_manager: DataManager)
Initializes QueryManager with a DataManager instance.
- Parameters:
  - data_manager: Instance of DataManager class
- Sets up logging

##### async execute_query(structured_criteria: Dict[str, Any], filter_current_cohort: bool = False) -> Dict[str, Any]
Executes a query based on structured criteria.
- Parameters:
  - structured_criteria: Dictionary containing parsed query parameters
  - filter_current_cohort: Boolean flag to determine if filter should be applied to current cohort (True) or reset cohort before filtering (False)
- Returns: Dictionary containing:
  - criteria: Original query criteria
  - row_count: Number of rows in result
  - filtered_from: Size of dataset before filtering
  - columns: List of available columns
  - filter_type: Either "current_cohort" or "new_search"
- Raises:
  - QueryExecutionError if execution fails
- Logs execution progress and results

##### get_last_query() -> Dict[str, Any]
Returns the criteria from the last executed query.
- Returns: Dictionary containing last query criteria

##### get_current_cohort_size() -> int
Returns the size of the current filtered cohort.
- Returns: Number of rows in current cohort

## Exceptions

### QueryExecutionError
Custom exception for query execution failures.
- Raised when query execution encounters errors


# cli.py

## Overview
Command-line interface for the Healthcare Data Analysis System. Provides interactive command processing and test execution capabilities. Built on Python's cmd module.

## Classes

### HealthcareCLI(cmd.Cmd)
Command-line interface handler inheriting from cmd.Cmd.

#### Properties
- `intro`: Welcome message displayed on startup
- `prompt`: Command prompt string showing "(Master Branch Bot)"
- `app`: Reference to main Application instance
- `tests_dir`: Path to the tests directory

#### Methods

##### __init__(application)
Initializes CLI interface.
- Parameters:
  - application: Reference to main Application instance
- Sets up logging and tests directory path

##### do_exit(self, arg)
Handles the 'exit' command to terminate the application.
- Returns: True to signal application exit
- Logs shutdown event

##### do_test(self, arg)
Handles test execution with interactive selection.
- Usage: test [file_name] [test_name]
- Features:
  - Interactive test file selection
  - Interactive test function selection
  - Option to run all tests
  - Shows numbered menu of available tests
  - Displays test execution results
- Parameters:
  - arg: Optional test file and function names

##### default(self, line)
Handles any input that isn't a specific command.
- Processes input as a query to the chatbot
- Parameters:
  - line: User input string
- Executes query asynchronously
- Displays query results or error message

##### emptyline(self)
Handles empty line input.
- Does nothing when user hits enter without input

##### do_help(self, arg)
Displays help information.
- Lists available commands:
  - test: Run test suite
  - exit: Exit application
  - help: Show help message
- Indicates that other input is treated as system queries


# logger.py

## Overview
Centralized logging configuration module for the project. Provides consistent logging setup across all components with proper formatting, file handling, and UTF-8 encoding support.

## Constants
- `LOG_FORMAT`: Format string for log messages ("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
- `DATE_FORMAT`: Format for timestamp in logs ("YYYY-MM-DD HH:MM:SS")
- `LOG_LEVEL`: Default logging level (INFO)
- `LOG_FILE_NAME`: Log file name pattern ("app_YYYYMMDD.log")
- `LOG_DIR`: Directory path for log files (project_root/logs/)

## Functions

### setup_logger(name: str, log_file: Optional[str] = None) -> logging.Logger
Creates and configures a logger instance.
- Parameters:
  - name: Logger name (typically __name__ from calling module)
  - log_file: Optional custom log file name
- Returns: Configured logging.Logger instance
- Features:
  - Creates logs directory if it doesn't exist
  - Sets up both file and console handlers
  - Uses UTF-8 encoding for all output
  - Applies consistent formatting to all log messages
  - Creates daily log files by default

## Global Variables
- `logger`: Default logger instance for the module

## Implementation Details
- Ensures UTF-8 encoding for stdout
- Uses pathlib for cross-platform path handling
- Supports both modern and legacy Python stdout handling
- Creates separate handlers for file and console output
- Maintains consistent formatting across all logging outputs


# config.py

## Overview
Central configuration module containing API keys and project-wide constants.

## Current Configuration
- `LLM_API_KEY`: API key for LLM service access

## Proposed Constants to Add
```python
# LLM Configuration
LLM_API_KEY = 'sk-3_O3H03UKNNxB5oVh_gabA'  # Should be moved to environment variable
LLM_DEFAULT_TEMPERATURE = 0.7
LLM_MAX_TOKENS = 150
LLM_TOP_P = 1.0
LLM_FREQUENCY_PENALTY = 0.0
LLM_PRESENCE_PENALTY = 0.0

# File Paths
DATA_DIR = 'data'
LOGS_DIR = 'logs'
TESTS_DIR = 'tests'

# Logging Configuration
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
DATE_FORMAT = "%Y-%m-%d %H:%M:%S"
LOG_LEVEL = "INFO"
LOG_FILE_PATTERN = "app_{date}.log"

# CLI Configuration
CLI_PROMPT = "(Master Branch Bot) "
CLI_INTRO = "Welcome to the Healthcare Data Analysis System. Type 'help' for commands."

# Query Processing
MAX_CACHE_SIZE = 1000  # Maximum number of cached queries
